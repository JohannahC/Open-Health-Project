---
title: "Protocol: industry relationships in guidelines (i-rig)"
date: "`r Sys.Date()`"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Overview

This document outlines the protocol for building the Industry Relationships in Guidelines (i-rig) dataset - which offers a way to explore corporate influence on the development of US clinical practice guidelines. For each guideline, I-RIG contains a history of the payments and gifts received (since 2013) by any author of an included guideline who's able to prescribe medication in the US.

## The protocol

For each guideline, there are 4 broad steps:

>1. Find the guideline  
>2. Extract the author names & relevant metadata 
>3. Match names to [National Provider Identifier](https://www.cms.gov/Regulations-and-Guidance/Administrative-Simplification/NationalProvIde>ntStand#:~:text=The%20NPI%20is%20a%20unique,financial%20transactions%20adopted%20under%20HIPAA.) (NPI) **and verify accuracy**
>4. For each author, link NPI to [US Open Payments Data](https://openpaymentsdata.cms.gov/)

To illustrate these steps, this document will walk through the data construction for the [2023 Guideline for the Management of Patients with Aneurysmal Subarachnoid Hemorrhage: A Guideline from the American Heart Association/American Stroke Association](https://www.ahajournals.org/doi/epdf/10.1161/STR.0000000000000436). However, keep in mind that the steps outlined here are designed to be completed programmatically at scale. 

### Step 1: find the guideline

The guideline is the starting point of all further data construction. We need it to figure out who the authors are, in order to then identify if and which payment records in Open Payments exist for these authors. 

**Guidelines can be found in many places including:**

- Directly on the webpage of the professional medical association (ex. [American Diabetes Association](https://diabetesjournals.org/care/issue/46/Supplement_1), [National Comprehensive Cancer Network](https://www.nccn.org/guidelines/nccn-guidelines), [American Heart Association/American College of Cardiology](https://professional.heart.org/en/guidelines-and-statements))
- Guideline databases ([ECRI Guidelines Trust](https://www.ecri.org/solutions/ecri-guidelines-trust), [Guideline Central](https://www.guidelinecentral.com/), [Guidelines International Network](https://g-i-n.net/)) that maintain curated, (though non-comprehensive lists) of guidelines
- Search engines for biomedical literature ([PubMed](https://pubmed.ncbi.nlm.nih.gov/)). Note: these are messy

**A focus on Digital Object Identifiers (DOI)**

Because what we ultimately want from the guideline is a list of all it's authors (and because we're doing this at scale), we're looking for each guideline's DOI, which will allow us to easily extract metadata for the publication via an API. Therefore, we're focused on optimizing our approach (and thus this protocol) for ways that facilitate batch DOIs harvesting. Our starting point in this project is an excel file obtained from the ECRI Guidelines Trust, which contains a list of all ~3,000 guidelines contained in their database. Many, though not all, guideline URLs in this list contain the DOI directly within it. Example: <https://www.ahajournals.org/doi/epdf/10.1161/STR.0000000000000436> and we are able to extract the DOI from the string, and construct a DOI list that can be fed into the API call. 

That said, DOIs may not be the only way to organize guidelines and harvest author metadata. The NCCN, for example, does not publish their guidelines with DOIs - but their guidelines offer other ways of easily harvesting author names (ie. webscraping). Details on all the unique ways of batch executing Step 1 will be described elsewhere. 

For now, let's proceed to step 2 with the DOI from our example guideline:

*10.1161/STR.0000000000000436*


### Step 2: extract the author names and relevant metadata

Step 2 consists of using the DOI to extract the metadata for the publication, in order to create a dataframe where each author gets their own row. The way to do this is to run the DOI through the Crossref API. Crossref maintains their API and there's an R package developed for easily accessing it **rcrossref**.

These helpful **rcrossref** guides were used here:

- Package/ Github repository <https://ciakovx.github.io/rcrossref.html#Searching_by_DOI>
- Corresponding Youtube Tutorial <https://www.youtube.com/watch?v=dy-raTcj0no>

Here's the step-by-step for our DOI

First, load packages:

```{r load-packages, eval=FALSE, echo=TRUE, cache=TRUE}
library(rcrossref)
library(usethis)
library(listviewer)
library(tidyverse)
library(dplyr)
library(purrr)
```

To adhere to Crossrefs polite-user policy, I provide them my email address when making the API call (stored in the ~/.Renviron)

```{r api-setup, eval=FALSE, echo=TRUE, cache=TRUE}
file.edit("~/.Renviron")
usethis::edit_r_environ()
```

Next, we store the DOI in a variable and then make the API call by passing it through cr_works() which is a **rcrossref** fucntion (in crossref, "works" refers to an individual article) in order to retrieve all the data associated with the DOI. The results are stored in my_dois_works.

```{r api-call , eval=FALSE, echo=TRUE, cache=TRUE}

doi <- "10.1161/STR.0000000000000436"
my_dois_works <- rcrossref::cr_works(dois = doi) %>%
  pluck("data")
``` 

Now, the author data needs to be unnested from the call dump, so that each author gets their own row in the new dataframe

```{r api-author-unnest , eval=FALSE, echo=TRUE, cache=TRUE}
# Unnest the author column into separate rows
my_dois_works <- my_dois_works %>%
  mutate(author = map(author, ~ as.data.frame(.))) %>%
  unnest(author)
``` 

After,  we clean it up so that we only keep the columns we're interested in for each author. In this case, the DOI, the guideline title, the journal, the date published, given and family names, along with suffix, affiliations, ORCID Id and urls. 

```{r api-cleanup , eval=FALSE, echo=TRUE, cache=TRUE}

authors_clean <- my_dois_works %>%
  select(doi, title, container.title, issued, given, family, suffix, affiliation.name,
         affiliation1.name,affiliation2.name, affiliation3.name,ORCID, link, url)

#forgot: unnest the link variable and extract the URL as link_url
authors_clean <- authors_clean %>%
  mutate(link_url = map_chr(link, ~pluck(., "URL")[1])) %>%
  select(-link)
``` 

Now we have a dataframe called **authors_clean** which contains all the author data for our guideline (first name, last name, suffix, affiliations, ORCID) along with the above information on the guideline (doi, title, journal, publication date, url). Lastly, we write the df to a csv so we can use it in Step 3. 

``` {r write-csv, eval=FALSE, echo=TRUE, cache=TRUE}

write.csv(authors_clean, "authors_clean.csv")
```

### Step 3: match names to National Provider Identifier (NPI) and verify accuracy

The objective of Step 3 is to match each author with the correct unique National Provier Identifier, where an NPI is available. An NPI should be available in all cases where an author has prescribing rights in the US (ie. a doctor, nurse practitioner, pharmacist).

To accurately match, we need to address the challenge of name variability between the name an author publishes under and the name the author registered their NPI with. Consider the fictitious author who publishes under the name "J. Michael Roberts", but who's NPI is registered as "John M. Roberts" or the author who's changed their last name after marriage, but continues to publish under their last name at birth. A simple name search in the NPI registry may mismatch or miss entirely these authors. 

To address this, this phase of the protocol necessitates both manual and programmatic work. 

***

**Overview:** this phase of the protocol consists of 3 steps:

1. **OP eligibility assessment**: 
Because there are cases in which a guideline author may not even be eligible to be in the Open Payments database, it's important that we identify and exclude these authors from our name matching step (lest we accidentally match them to someone else's NPI in the registry because they share a name, and unkowingly search the payments data for the wrong person). Authors will not be in the OP data if they: do not have prescribing rights or have never worked as a healthcare provider in the US.

2. **Fetch potential matches using NPPES API**:
The names of eligible authors are queried in the NPPES API, which enables access to the up-to-date list of everyone with an NPI number and relevant identifying information about them (practice location, licensure, medical specialty, other names, and more).

3. **The NPI verification**: 
select name matches are combed manually once again against specified criteria, to ensure the author is paired with the correct NPI 


***

1. **OP eligibility assessment**
This is a manual step that involves checking the publication and each author for:

- a prescribing credential or a degree that would allow someone to sit a licensure exam. These include:
    + MD
    + DO
    + NP
    + DDS
    + DNP
    + PharmD
    + PA
    + CNM
    + CNS
    + CRNA
    + MBBS (this is a UK MD equivalent)
- a US employer
    + as determined by affiliation on publication (in our example, see Appendix 1)
- for cases where there is a non-US employer or affiliation, but there is a prescribing credential:
    + a manual internet search is undertaken to assess if the author could have previously held US licensure:
    + such as: a former US affiliation, medical school, etc

*** 
Non-US author classification checklist: 

- If a = true, b = false and c = true, then “OP eligibility = true”.
- If a = true, b = false and c = false, then “OP eligibility = false”.

***

  
*If an author is OP-eligible, proceed to step 2*


2. **Fetch potential matches using NPPES API**: 
Using the NPPES API, fetch potential NPI matches for the author, *iterating on all possible names.* 
(see more on this - touch base again with jo to get notes on steps taken)

3. **NPI Verification**:

*non-manual*

    - If only one match is returned, assume it is the correct person.
    - If multiple matches are returned, proceed to step 4.
    
*manual combing*  

For each author with multiple potential NPI matches, manually cross-check the information we know about them against the items in this list where it is available, prioritizing in descending order (order of most reliable information), ensuring at least 3 of the top 4 items match, and only 1 reasonable match remains. In cases of uncertainty, proceed further down the list:

    - Matching credential
    - Matching practice state with state of affiliation/employer on publication
    - Matching taxonomy (medical specialty)
    - Matching middle names, initials, or other names 
    - If more than one match within the same state, check further location details for more accurate address matching
    - If there is a mismatch in practice location or other items on this list, and it is presumed it still may be the correct person, check for other sources linking the author to the NPI (faculty page, author's professional profile, etc.).
    - See if the guideline/publication in question is listed on their faculty or patient website's publication page.
    - Confirm similarities in specialties/research interests between what you can find about the author and the NPI profile
    - Look for other professional affiliations that might help confirm the match
    - Look for matching medical school or other educational information

*author outreach*

If we cannot confidently identify the NPI match, make an attempt to email the person directly to confirm their NPI.

*list unverified matches as NA*

### Step 4: for each author, link NPI to [US Open Payments Data](https://openpaymentsdata.cms.gov/)

linky link link



